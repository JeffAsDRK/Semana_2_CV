{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730c5168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   name           frame                combined\n",
      "0  gran_paradiso_island  frame_0000.png  mask_combined_0000.png\n",
      "1  gran_paradiso_island  frame_0001.png  mask_combined_0001.png\n",
      "2  gran_paradiso_island  frame_0002.png  mask_combined_0002.png\n",
      "3  gran_paradiso_island  frame_0003.png  mask_combined_0003.png\n",
      "4  gran_paradiso_island  frame_0004.png  mask_combined_0004.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "base_path = 'dense_data'\n",
    "data = []\n",
    "\n",
    "def extract_index(filename):\n",
    "    \"\"\"Extrae el número del archivo, por ejemplo 'frame_0159.png' -> '0159'\"\"\"\n",
    "    match = re.search(r'(\\d+)', filename)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "for level_name in os.listdir(base_path):\n",
    "    level_path = os.path.join(base_path, level_name)\n",
    "    if not os.path.isdir(level_path):\n",
    "        continue\n",
    "\n",
    "    frame_path = os.path.join(level_path, 'frame')\n",
    "    combined_path = os.path.join(level_path, 'combined')\n",
    "\n",
    "    frames = {}\n",
    "    combineds = {}\n",
    "\n",
    "    # Leer frames\n",
    "    if os.path.isdir(frame_path):\n",
    "        for fname in os.listdir(frame_path):\n",
    "            index = extract_index(fname)\n",
    "            if index:\n",
    "                frames[index] = fname\n",
    "\n",
    "    # Leer combined visuals\n",
    "    if os.path.isdir(combined_path):\n",
    "        for cname in os.listdir(combined_path):\n",
    "            index = extract_index(cname)\n",
    "            if index:\n",
    "                combineds[index] = cname\n",
    "\n",
    "    # Buscar coincidencias exactas por índice\n",
    "    for index in sorted(set(frames.keys()) & set(combineds.keys())):\n",
    "        data.append({\n",
    "            \"name\": level_name,\n",
    "            \"frame\": frames[index],\n",
    "            \"combined\": combineds[index]\n",
    "        })\n",
    "\n",
    "# Crear DataFrame final\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28ab5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import UNet, TransferSegmentation, save_model, load_model\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torchvision.transforms import v2 \n",
    "from utils_jeff import Load_Dataset\n",
    "import torch.utils.tensorboard as tb \n",
    "import numpy as np\n",
    "\n",
    "random_state=42\n",
    "torch.manual_seed(random_state)\n",
    "\n",
    "\n",
    "def post_proces(predicted_logits):\n",
    "    predicted_mask = torch.argmax(predicted_logits, dim=1)  # [B, H, W]\n",
    "    return predicted_mask\n",
    "\n",
    "def calculate_multiclass_iou_f1(predicted_logits, target_mask, num_classes, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Calcula el IoU y el F1-score por clase y sus promedios (mIoU, macro-F1).\n",
    "\n",
    "    Args:\n",
    "        predicted_logits: Tensor [B, C, H, W] (output sin softmax)\n",
    "        target_mask: Tensor [B, H, W] con valores enteros de clase\n",
    "        num_classes: Total de clases\n",
    "    Returns:\n",
    "        mean_iou: Promedio de IoU entre clases\n",
    "        mean_f1: Promedio de F1 entre clases\n",
    "    \"\"\"\n",
    "    predicted_mask= post_proces(predicted_logits)\n",
    "\n",
    "    ious = []\n",
    "    f1s = []\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        pred_cls = (predicted_mask == cls)\n",
    "        target_cls = (target_mask == cls)\n",
    "\n",
    "        intersection = (pred_cls & target_cls).sum().float()\n",
    "        union = (pred_cls | target_cls).sum().float()\n",
    "\n",
    "        # IoU\n",
    "        iou = (intersection + epsilon) / (union + epsilon)\n",
    "        ious.append(iou)\n",
    "\n",
    "        # F1-score\n",
    "        tp = intersection\n",
    "        fp = (pred_cls & ~target_cls).sum().float()\n",
    "        fn = (~pred_cls & target_cls).sum().float()\n",
    "        f1 = (2 * tp + epsilon) / (2 * tp + fp + fn + epsilon)\n",
    "        f1s.append(f1)\n",
    "\n",
    "    mean_iou = torch.mean(torch.tensor(ious))\n",
    "    mean_f1 = torch.mean(torch.tensor(f1s))\n",
    "\n",
    "    return mean_iou.item(), mean_f1.item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace2eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de clases\n",
    "NUM_CLASSES = 7\n",
    "# Inicializar contador de clases\n",
    "pixel_counts = np.zeros(NUM_CLASSES, dtype=np.int64)\n",
    "import cv2\n",
    "# Recorremos todas las máscaras\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    mask_path = f\"./{base_path}/{row['name']}/combined/{row['combined']}\"\n",
    "    mask = cv2.imread(mask_path)\n",
    "    mask=cv2.cvtColor(mask,cv2.COLOR_BGR2GRAY)  # matriz de clases (HxW)\n",
    "    # Contar ocurrencias de cada clase\n",
    "    unique, counts = np.unique(mask, return_counts=True)\n",
    "    for cls, cnt in zip(unique, counts):\n",
    "        if cls < NUM_CLASSES:\n",
    "            pixel_counts[cls] += cnt\n",
    "\n",
    "# Calcular pesos inversos (más peso a clases menos frecuentes)\n",
    "class_weights = 1.0 / (pixel_counts + 1e-6)  # para evitar división por cero\n",
    "class_weights = class_weights / class_weights.sum() * NUM_CLASSES  # normalizar\n",
    "\n",
    "# Convertir a tensor para usar en CrossEntropyLoss\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "084bc0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransferSegmentation(n_classes=7)\n",
    "\n",
    "datase = Load_Dataset(df, base_path, batch_size=512, aumentation=8, num_workers=16)\n",
    "transform = model.weights.transforms() # resulta mejor con la transformacion propia\n",
    "\n",
    "\n",
    "train_loader = datase.load_train(transform=transform)\n",
    "val_loader = datase.load_val(transform=transform)\n",
    "test_loader = datase.load_test(transform=transform)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor.to(device)) # aplica sigmoid directamente sobre los logits del modelo\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "209ee876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        device,\n",
    "        log_dir=None,\n",
    "        num_classes=7,\n",
    "        max_epochs=200,\n",
    "        max_patience=25,\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        self.max_epochs = max_epochs\n",
    "        self.max_patience = max_patience\n",
    "\n",
    "        self.best_iou = 0\n",
    "        self.patience = 0\n",
    "        self.global_step = 0\n",
    "        self.writer = SummaryWriter(log_dir, flush_secs=1) if log_dir else None\n",
    "        self.val_stoping=0\n",
    "        self.train_stoping=0\n",
    "\n",
    "    def train(self):\n",
    "        print(f\"{'Epoch':<7}{'Phase':<8}{'Loss':<10}{'mIoU (%)':<10}{'F1 (%)':<10}\")\n",
    "        print(\"=\" * 45)\n",
    "        for epoch in range(self.max_epochs):\n",
    "            epoch_loss, epoch_iou, epoch_f1 = self.train_one_epoch(epoch)\n",
    "    \n",
    "            self.scheduler.step(epoch_iou)\n",
    "    \n",
    "            # Evaluación después de entrenamiento\n",
    "            val_iou, val_f1 = self.evaluate(epoch)\n",
    "    \n",
    "            # Mostrar resumen en columna\n",
    "            print(f\"{epoch+1:<7}{'Train':<8}{epoch_loss:<10.4f}{epoch_iou:<10.2f}{epoch_f1:<10.2f}\")\n",
    "            print(f\"{'':<7}{'Val':<8}{'-':<10}{val_iou:<10.2f}{val_f1:<10.2f}\")\n",
    "    \n",
    "            # TensorBoard logging\n",
    "            if self.writer:\n",
    "                self.writer.add_scalar(\"epoch_loss\", epoch_loss, epoch)\n",
    "                self.writer.add_scalar(\"epoch_mean_iou\", epoch_iou, epoch)\n",
    "                self.writer.add_scalar(\"epoch_mean_f1\", epoch_f1, epoch)\n",
    "                self.writer.add_scalar(\"val_mean_iou\", val_iou, epoch)\n",
    "                self.writer.add_scalar(\"val_mean_f1\", val_f1, epoch)\n",
    "                self.writer.add_scalar(\"epoch_lr\", self.optimizer.param_groups[0][\"lr\"], epoch)\n",
    "    \n",
    "            # Guardado del mejor modelo\n",
    "            \n",
    "            if val_iou > self.best_iou:\n",
    "                self.save_model(\"TransferSegmentation_Jeff.th\")\n",
    "                self.best_iou = val_iou\n",
    "                self.patience = 0\n",
    "\n",
    "            if val_iou < self.val_stoping:\n",
    "               if epoch_iou > self.train_stoping:\n",
    "                   self.train_stoping=epoch_iou\n",
    "                   self.patience=0\n",
    "               else:\n",
    "                   self.patience+=1 \n",
    "            else: \n",
    "                self.val_stoping=val_iou\n",
    "                self.patience=0\n",
    "    \n",
    "            if self.patience >= self.max_patience:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "\n",
    "    def train_one_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        running_loss = 0\n",
    "        ious, f1 = [], []\n",
    "        total = len(self.train_loader)\n",
    "\n",
    "        for i, (inputs, targets) in enumerate(self.train_loader):\n",
    "            print(f\"Train Epoch {epoch+1}  {(i+1)*100/total:.2f}%\", end=\"\\r\")\n",
    "            inputs = inputs.to(self.device,non_blocking=True)\n",
    "            targets = targets.long().squeeze().to(self.device,non_blocking=True)\n",
    "\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            batch_iou, f1_score = calculate_multiclass_iou_f1(\n",
    "                outputs, targets, self.num_classes\n",
    "            )\n",
    "            ious.append(batch_iou)\n",
    "            f1.append(f1_score)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        mean_iou = np.mean(ious) * 100\n",
    "        mean_f1 = np.mean(f1) * 100\n",
    "        avg_loss = running_loss / total\n",
    "        return avg_loss, mean_iou, mean_f1\n",
    "\n",
    "\n",
    "    def evaluate(self, epoch):\n",
    "        self.model.eval()\n",
    "        ious, f1 = [], []\n",
    "        total = len(self.val_loader)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, targets) in enumerate(self.val_loader):\n",
    "                print(f\"Val   Epoch {epoch+1}  {(i+1)*100/total:.2f}%\", end=\"\\r\")\n",
    "                inputs = inputs.to(self.device,non_blocking=True)\n",
    "                targets = targets.long().squeeze().to(self.device,non_blocking=True)\n",
    "\n",
    "                outputs = self.model(inputs)\n",
    "                batch_iou, f1_score = calculate_multiclass_iou_f1(\n",
    "                    outputs, targets, self.num_classes\n",
    "                )\n",
    "                ious.append(batch_iou)\n",
    "                f1.append(f1_score)\n",
    "            print()\n",
    "\n",
    "        mean_iou = np.mean(ious) * 100\n",
    "        mean_f1 = np.mean(f1) * 100\n",
    "\n",
    "        if self.writer:\n",
    "            self.writer.add_scalar(\"val_mean_iou\", mean_iou, epoch)\n",
    "            self.writer.add_scalar(\"val_mean_f1\", mean_f1, epoch)\n",
    "            vis_targets = targets.unsqueeze(1) * 32 / 255\n",
    "            pred_mask = post_proces(outputs)\n",
    "            vis_outputs = pred_mask.unsqueeze(1) * 32 / 255\n",
    "            self.writer.add_images(\"val/image\", inputs[:6].cpu(), epoch)\n",
    "            self.writer.add_images(\"val/label\", vis_targets[:6].cpu(), epoch)\n",
    "            self.writer.add_images(\"val/pred\", vis_outputs[:6].cpu(), epoch)\n",
    "\n",
    "            if self.global_step == 0:\n",
    "                self.writer.add_graph(self.model, inputs)\n",
    "        self.global_step += 1\n",
    "        return mean_iou, mean_f1\n",
    "\n",
    "\n",
    "    def save_model(self, filename):\n",
    "        torch.save(self.model.state_dict(), filename)\n",
    "        print(f\"Modelo guardado como {filename}\")\n",
    "\n",
    "log_dir = f'semantic_segmentation/runs/{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}' \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee00ae55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  Phase   Loss      mIoU (%)  F1 (%)    \n",
      "=============================================\n",
      "Val   Epoch 1  100.00%\n",
      "1      Train   1.4107    15.22     22.30     \n",
      "       Val     -         16.12     17.61     \n",
      "Modelo guardado como TransferSegmentation_Jeff.th\n",
      "Val   Epoch 2  100.00%\n",
      "2      Train   0.8658    20.85     28.68     \n",
      "       Val     -         35.14     44.24     \n",
      "Modelo guardado como TransferSegmentation_Jeff.th\n",
      "Val   Epoch 3  100.00%\n",
      "3      Train   0.7056    22.87     30.60     \n",
      "       Val     -         28.62     36.57     \n",
      "Val   Epoch 4  100.00%\n",
      "4      Train   0.6361    24.92     32.56     \n",
      "       Val     -         28.23     36.07     \n",
      "Val   Epoch 5  100.00%\n",
      "5      Train   0.5859    26.91     34.58     \n",
      "       Val     -         26.96     34.79     \n",
      "Val   Epoch 6  100.00%\n",
      "6      Train   0.5780    27.68     35.16     \n",
      "       Val     -         28.86     36.19     \n",
      "Val   Epoch 7  100.00%\n",
      "7      Train   0.5444    29.16     36.68     \n",
      "       Val     -         28.59     36.04     \n",
      "Val   Epoch 8  100.00%\n",
      "8      Train   0.5328    30.00     37.44     \n",
      "       Val     -         29.24     35.95     \n",
      "Val   Epoch 9  100.00%\n",
      "9      Train   0.5381    30.19     37.51     \n",
      "       Val     -         31.14     38.62     \n",
      "Val   Epoch 10  100.00%\n",
      "10     Train   0.5131    31.12     38.61     \n",
      "       Val     -         32.13     40.01     \n",
      "Val   Epoch 11  100.00%\n",
      "11     Train   0.5064    31.69     39.08     \n",
      "       Val     -         32.49     40.35     \n",
      "Val   Epoch 12  100.00%\n",
      "12     Train   0.5007    33.17     40.48     \n",
      "       Val     -         32.86     40.59     \n",
      "Val   Epoch 13  100.00%\n",
      "13     Train   0.4832    32.70     40.23     \n",
      "       Val     -         34.04     42.01     \n",
      "Val   Epoch 14  100.00%\n",
      "14     Train   0.4809    34.33     41.83     \n",
      "       Val     -         30.36     37.40     \n",
      "Val   Epoch 15  100.00%\n",
      "15     Train   0.4670    34.70     42.23     \n",
      "       Val     -         32.48     39.98     \n",
      "Val   Epoch 16  100.00%\n",
      "16     Train   0.4733    33.55     41.09     \n",
      "       Val     -         35.52     43.54     \n",
      "Modelo guardado como TransferSegmentation_Jeff.th\n",
      "Val   Epoch 17  100.00%\n",
      "17     Train   0.4609    33.93     41.42     \n",
      "       Val     -         36.17     44.51     \n",
      "Modelo guardado como TransferSegmentation_Jeff.th\n",
      "Val   Epoch 18  100.00%\n",
      "18     Train   0.4454    34.86     42.61     \n",
      "       Val     -         37.00     45.55     \n",
      "Modelo guardado como TransferSegmentation_Jeff.th\n",
      "Val   Epoch 19  100.00%\n",
      "19     Train   0.4427    36.41     44.02     \n",
      "       Val     -         35.05     42.91     \n",
      "Val   Epoch 20  100.00%\n",
      "20     Train   0.4479    36.85     44.29     \n",
      "       Val     -         28.34     35.57     \n",
      "Val   Epoch 21  100.00%\n",
      "21     Train   0.4673    35.28     42.42     \n",
      "       Val     -         36.52     44.72     \n",
      "Val   Epoch 22  100.00%\n",
      "22     Train   0.4295    35.51     43.19     \n",
      "       Val     -         38.20     46.48     \n",
      "Modelo guardado como TransferSegmentation_Jeff.th\n",
      "Val   Epoch 23  100.00%\n",
      "23     Train   0.4273    35.94     43.68     \n",
      "       Val     -         37.24     45.44     \n",
      "Val   Epoch 24  100.00%\n",
      "24     Train   0.4281    36.13     43.86     \n",
      "       Val     -         38.37     46.69     \n",
      "Modelo guardado como TransferSegmentation_Jeff.th\n",
      "Val   Epoch 25  100.00%\n",
      "25     Train   0.4181    37.82     45.66     \n",
      "       Val     -         36.96     44.95     \n",
      "Train Epoch 26  76.92%\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-319ff0c872ac>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmax_patience\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-f04e0a72f13d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mepoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_iou\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iou\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f04e0a72f13d>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             batch_iou, f1_score = calculate_multiclass_iou_f1(\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             )\n",
      "\u001b[0;32m<ipython-input-2-fb9a7dd338fc>\u001b[0m in \u001b[0;36mcalculate_multiclass_iou_f1\u001b[0;34m(predicted_logits, target_mask, num_classes, epsilon)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mf1s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mmean_iou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mious\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mmean_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    log_dir=log_dir,\n",
    "    num_classes=7,\n",
    "    max_epochs=500,\n",
    "    max_patience= 25,\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
